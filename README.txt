1. Скрипт для парсинга сайта TNVED

Описание
Этот скрипт предназначен для парсинга сайта TNVED и сохранения собранных данных в файлы форматов JSON и Excel.

Запуск скрипта
Клонируйте репозиторий на ваш локальный компьютер:
git clone https://github.com/mrewrin/ocsd_test.git
cd ocsd_test

Установите зависимости:
pip install -r requirements.txt

Запустите скрипт:
scrapy runspider tnved_spider.py

Описание файлов
tnved_spider.py: основной файл скрипта, содержащий логику парсинга.
requirements.txt: файл для установки всех необходимых зависимостей.

Примечания
Убедитесь, что у вас установлен Google Chrome и ChromeDriver.
При возникновении проблем с ChromeDriver, вы можете загрузить его вручную с официального сайта: https://sites.google.com/a/chromium.org/chromedriver/downloads
Обновите путь к ChromeDriver в скрипте tnved_spider.py при необходимости.


2. Взаимодействие с парсером JSON файлов

Запуск скрипта для парсинга JSON файлов
Скрипт parser.py предназначен для парсинга JSON-файлов, используемых в визуализациях отчетов PowerBI, и сохранения собранных данных в формате Excel.

Установка зависимостей
pip install pandas openpyxl

Запуск скрипта
python parser.py

Описание файлов
parser.py: основной файл скрипта, содержащий логику парсинга JSON-файлов.
requirements.txt: файл для установки всех необходимых зависимостей.


Результаты работы обоих скриптов вынесены в папку Results для удобства.
Если у вас возникнут вопросы или предложения, пожалуйста, свяжитесь со мной.